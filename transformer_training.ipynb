{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "transformer_training.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPaDApKdvUjnd8MuC4NiCfR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/simonEllershaw/latent_variable_OOD/blob/main/transformer_training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DvBiYfvE6O1G",
        "outputId": "6878206b-73b4-4e4e-c834-a182d7b776f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pip in /usr/local/lib/python3.7/dist-packages (21.1.3)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.16.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.10.0+cu111)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.47)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.2)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.11.5)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.4.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n"
          ]
        }
      ],
      "source": [
        "! pip install pip transformers torch\n",
        "# ! pip install -q kaggle"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ! mkdir ~/.kaggle\n",
        "# ! cp kaggle.json ~/.kaggle/\n",
        "# ! chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "v1HaE2L98QYs"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ! kaggle datasets download tboyle10/medicaltranscriptions -p data/\n",
        "# ! unzip data/clinc150_uci.zip -d data"
      ],
      "metadata": {
        "id": "L_m6ZPt-9ZD1"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "with open('/content/data/clinc150_uci/data_full.json') as f:\n",
        "  data = json.load(f)"
      ],
      "metadata": {
        "id": "2KCl3NUu8Ovl"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fcxfnd8N9BSh",
        "outputId": "dc19aa17-3946-451e-d928-4f0cb2e3ffec"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['oos_val', 'val', 'train', 'oos_test', 'test', 'oos_train'])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "in_scope_data = {k: v for k,v in data.items() if 'oos' not in k}"
      ],
      "metadata": {
        "id": "GpR-QDSC9dnl"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "AQK4sFJG9cxl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "checkpoint = \"roberta-base\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
      ],
      "metadata": {
        "id": "0HRmKobDILmH"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "in_scope_data['train'][:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xmjNobSU967f",
        "outputId": "33a09a7d-b09b-4a77-ec6c-77c9ded67786"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['what expression would i use to say i love you if i were an italian',\n",
              "  'translate'],\n",
              " [\"can you tell me how to say 'i do not speak much spanish', in spanish\",\n",
              "  'translate'],\n",
              " [\"what is the equivalent of, 'life is good' in french\", 'translate'],\n",
              " [\"tell me how to say, 'it is a beautiful morning' in italian\", 'translate'],\n",
              " ['if i were mongolian, how would i say that i am a tourist', 'translate'],\n",
              " [\"how do i say 'hotel' in finnish\", 'translate'],\n",
              " [\"i need you to translate the sentence, 'we will be there soon' into portuguese\",\n",
              "  'translate'],\n",
              " ['please tell me how to ask for a taxi in french', 'translate'],\n",
              " [\"can you tell me how i would say, 'more bread please' in french\",\n",
              "  'translate'],\n",
              " [\"what is the correct way to say 'i am a visitor' in french\", 'translate']]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "\n",
        "class HuggingFaceDataset(Dataset):\n",
        "  def __init__(self, texts, labels, label2id, tokenizer):\n",
        "    self._dict = tokenizer(texts, truncation=True)\n",
        "    self._dict['labels'] = [label2id[label] for label in labels]\n",
        "\n",
        "  def __len__(self):\n",
        "        return len(self._dict[\"input_ids\"])\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "      return {k: v[idx] for k, v in self._dict.items()}\n",
        "\n",
        "label_names = sorted({label for _, label in in_scope_data['train']})\n",
        "id2label = dict(enumerate(sorted(label_names)))\n",
        "label2id = {v: k for k, v in id2label.items()}\n",
        "\n",
        "datasets_hf = {}\n",
        "for key, dataset in in_scope_data.items():\n",
        "  texts, labels = map(list,zip(*dataset))\n",
        "  datasets_hf[key] = HuggingFaceDataset(texts, labels, label2id, tokenizer) "
      ],
      "metadata": {
        "id": "-lmnAdNNEjqi"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.hist([len(sample['input_ids']) for sample in datasets_hf['train']])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        },
        "id": "ueVQCkDht6Yk",
        "outputId": "86605712-3742-4c47-f866-3cdd1126ff7d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([1.013e+03, 4.410e+03, 6.366e+03, 2.022e+03, 7.220e+02, 3.610e+02,\n",
              "        6.800e+01, 3.200e+01, 4.000e+00, 2.000e+00]),\n",
              " array([ 3. ,  6.4,  9.8, 13.2, 16.6, 20. , 23.4, 26.8, 30.2, 33.6, 37. ]),\n",
              " <a list of 10 Patch objects>)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSequenceClassification\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    checkpoint,\n",
        "    id2label=id2label,\n",
        "    label2id=label2id,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "no8WjPFcRsKd",
        "outputId": "98a13505-3597-4f33-c590-082f62b15604"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'roberta.pooler.dense.bias', 'roberta.pooler.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.weight']\n",
            "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments\n",
        "\n",
        "args = TrainingArguments(\n",
        "    \"inscope_text_classification\",\n",
        "    per_device_train_batch_size=32,\n",
        "    per_device_eval_batch_size=32,\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    logging_strategy=\"epoch\",\n",
        "    learning_rate=5e-5,\n",
        "    num_train_epochs=10,\n",
        "    weight_decay=0.01,\n",
        "    group_by_length=True,\n",
        "    warmup_ratio=0.1,\n",
        "    load_best_model_at_end=True\n",
        ")\n"
      ],
      "metadata": {
        "id": "w1tvUeaNR4eo"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "import numpy as np\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "  \"\"\"Called to compute validation metrics at each evaluation step of training.\"\"\"\n",
        "  logits, labels = eval_pred\n",
        "  labels = labels.flatten()\n",
        "  predictions = np.argmax(logits, axis=-1).flatten()\n",
        "\n",
        "  precision, recall, f1, _ = precision_recall_fscore_support(\n",
        "      labels, predictions, average='macro', zero_division=0\n",
        "  )\n",
        "  metrics = {\"f1\": f1, \"precision\": precision, \"recall\": recall}\n",
        "  return metrics"
      ],
      "metadata": {
        "id": "N37ouBZxS4hs"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Trainer, DataCollatorWithPadding, EarlyStoppingCallback\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=args,\n",
        "    train_dataset=datasets_hf['train'],\n",
        "    eval_dataset=datasets_hf['val'],\n",
        "    data_collator=DataCollatorWithPadding(tokenizer),\n",
        "    compute_metrics=compute_metrics,\n",
        "    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)],\n",
        ")\n",
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "IStnRUjESgUZ",
        "outputId": "6d3c98b4-dcc0-415d-a2af-6bdda3cb9ccf"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 15000\n",
            "  Num Epochs = 10\n",
            "  Instantaneous batch size per device = 32\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 4690\n",
            "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msimon_ellershaw\u001b[0m (use `wandb login --relogin` to force relogin)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                    Syncing run <strong><a href=\"https://wandb.ai/simon_ellershaw/huggingface/runs/17kveljx\" target=\"_blank\">inscope_text_classification</a></strong> to <a href=\"https://wandb.ai/simon_ellershaw/huggingface\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
              "\n",
              "                "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='4690' max='4690' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [4690/4690 10:59, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>3.507900</td>\n",
              "      <td>1.038306</td>\n",
              "      <td>0.903988</td>\n",
              "      <td>0.915600</td>\n",
              "      <td>0.907333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.469100</td>\n",
              "      <td>0.221534</td>\n",
              "      <td>0.962404</td>\n",
              "      <td>0.965474</td>\n",
              "      <td>0.962667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.108800</td>\n",
              "      <td>0.170812</td>\n",
              "      <td>0.965189</td>\n",
              "      <td>0.967871</td>\n",
              "      <td>0.965333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.050000</td>\n",
              "      <td>0.182443</td>\n",
              "      <td>0.966577</td>\n",
              "      <td>0.969988</td>\n",
              "      <td>0.966333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.033600</td>\n",
              "      <td>0.170132</td>\n",
              "      <td>0.971933</td>\n",
              "      <td>0.973894</td>\n",
              "      <td>0.972000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.020400</td>\n",
              "      <td>0.163326</td>\n",
              "      <td>0.972200</td>\n",
              "      <td>0.974271</td>\n",
              "      <td>0.972333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.014200</td>\n",
              "      <td>0.160175</td>\n",
              "      <td>0.973853</td>\n",
              "      <td>0.975546</td>\n",
              "      <td>0.974000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.008700</td>\n",
              "      <td>0.167610</td>\n",
              "      <td>0.975209</td>\n",
              "      <td>0.977163</td>\n",
              "      <td>0.975333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.006900</td>\n",
              "      <td>0.166190</td>\n",
              "      <td>0.975937</td>\n",
              "      <td>0.977739</td>\n",
              "      <td>0.976000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.005000</td>\n",
              "      <td>0.167297</td>\n",
              "      <td>0.975598</td>\n",
              "      <td>0.977366</td>\n",
              "      <td>0.975667</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 3000\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to inscope_text_classification/checkpoint-469\n",
            "Configuration saved in inscope_text_classification/checkpoint-469/config.json\n",
            "Model weights saved in inscope_text_classification/checkpoint-469/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 3000\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to inscope_text_classification/checkpoint-938\n",
            "Configuration saved in inscope_text_classification/checkpoint-938/config.json\n",
            "Model weights saved in inscope_text_classification/checkpoint-938/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 3000\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to inscope_text_classification/checkpoint-1407\n",
            "Configuration saved in inscope_text_classification/checkpoint-1407/config.json\n",
            "Model weights saved in inscope_text_classification/checkpoint-1407/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 3000\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to inscope_text_classification/checkpoint-1876\n",
            "Configuration saved in inscope_text_classification/checkpoint-1876/config.json\n",
            "Model weights saved in inscope_text_classification/checkpoint-1876/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 3000\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to inscope_text_classification/checkpoint-2345\n",
            "Configuration saved in inscope_text_classification/checkpoint-2345/config.json\n",
            "Model weights saved in inscope_text_classification/checkpoint-2345/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 3000\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to inscope_text_classification/checkpoint-2814\n",
            "Configuration saved in inscope_text_classification/checkpoint-2814/config.json\n",
            "Model weights saved in inscope_text_classification/checkpoint-2814/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 3000\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to inscope_text_classification/checkpoint-3283\n",
            "Configuration saved in inscope_text_classification/checkpoint-3283/config.json\n",
            "Model weights saved in inscope_text_classification/checkpoint-3283/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 3000\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to inscope_text_classification/checkpoint-3752\n",
            "Configuration saved in inscope_text_classification/checkpoint-3752/config.json\n",
            "Model weights saved in inscope_text_classification/checkpoint-3752/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 3000\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to inscope_text_classification/checkpoint-4221\n",
            "Configuration saved in inscope_text_classification/checkpoint-4221/config.json\n",
            "Model weights saved in inscope_text_classification/checkpoint-4221/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 3000\n",
            "  Batch size = 32\n",
            "Saving model checkpoint to inscope_text_classification/checkpoint-4690\n",
            "Configuration saved in inscope_text_classification/checkpoint-4690/config.json\n",
            "Model weights saved in inscope_text_classification/checkpoint-4690/pytorch_model.bin\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Loading best model from inscope_text_classification/checkpoint-3283 (score: 0.16017483174800873).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=4690, training_loss=0.42247336266645746, metrics={'train_runtime': 664.0677, 'train_samples_per_second': 225.881, 'train_steps_per_second': 7.063, 'total_flos': 883268415517824.0, 'train_loss': 0.42247336266645746, 'epoch': 10.0})"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    }
  ]
}